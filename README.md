# Awesome Dichotomous Image Segmentation 
üî• A curated list of awesome resources for dichotomous image segmentation (DIS).

‚ùóUpdated at 2024-08-28.
## Content:
- [Dichotomous-Image-Segmentation](#Dichotomous-Image-Segmentation)
- [Non-Prompt](#Non-Prompt)
- [Promptable](#Promptable)
## Dichotomous-Image-Segmentation
### 2022
| **Year** | **Pub.** | **Title**                                      | **Author**                                                                                    | **Links**                                                                                                                                                                                                                                                                        |
| -------- | -------- | ---------------------------------------------- | --------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2022     | ECCV     | Highly Accurate Dichotomous Image Segmentation | Qin, Xuebin and Dai, Hang and Hu, Xiaobin and Fan, Deng-Ping and Shao, Ling and Van Gool, Luc | [Paper]([[2203.03041] Highly Accurate Dichotomous Image Segmentation (arxiv.org)](https://arxiv.org/abs/2203.03041))/[Code]([xuebinqin/DIS: This is the repo for our new project Highly Accurate Dichotomous Image Segmentation (github.com)](https://github.com/xuebinqin/DIS)) |

## Non-Prompt
### Preprint

| **Year** | **Pub.** | **Title**                                                               | **Author**                                                                                             | **Links**                                                                                                                                          |
| -------- | -------- | ----------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2024     | arXiv    | Diffusion Models Trained with Large Data Are Transferable Visual Models | Guangkai Xu, Yongtao Ge, Mingyu Liu, Chengxiang Fan, Kangyang Xie, Zhiyue Zhao, Hao Chen, Chunhua Shen | [Paper]([[2403.06090] Diffusion Models Trained with Large Data Are Transferable Visual Models (arxiv.org)](https://arxiv.org/abs/2403.06090))/Code |
### 2024
| **Year** | **Pub.** | **Title**                                                                        | **Author**                                                                              | **Links**                                                                                                                                                                                                                                                                                                                                                                                                      |
| -------- | -------- | -------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2024     | CVPR     | Multi-view Aggregation Network for Dichotomous Image Segmentation                | Qian Yu, Xiaoqi Zhao, Youwei Pang, Lihe Zhang, Huchuan Lu                               | [Paper]([CVPR 2024 Open Access Repository (thecvf.com)](https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Multi-view_Aggregation_Network_for_Dichotomous_Image_Segmentation_CVPR_2024_paper.html))/[Code]([CVPR 2024 Open Access Repository (thecvf.com)](https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Multi-view_Aggregation_Network_for_Dichotomous_Image_Segmentation_CVPR_2024_paper.html)) |
| 2024     | CAAI     | Bilateral Reference for High-Resolution Dichotomous Image Segmentation           | Peng Zheng, Dehong Gao, Deng-Ping Fan, Li Liu, Jorma Laaksonen, Wanli Ouyang, Nicu Sebe | [Paper]([[2401.03407] Bilateral Reference for High-Resolution Dichotomous Image Segmentation (arxiv.org)](https://arxiv.org/abs/2401.03407))/[Code]([ZhengPeng7/BiRefNet: [CAAI AIR'24] Bilateral Reference for High-Resolution Dichotomous Image Segmentation (github.com)](https://github.com/ZhengPeng7/BiRefNet))                                                                                          |
| 2024     | TNNLs    | High-Precision Dichotomous Image Segmentation With Frequency and Scale Awareness | Qiuping Jiang, Jinguang Cheng, Zongwei Wu, Runmin Cong, Radu Timofte                    | [Paper]([High-Precision Dichotomous Image Segmentation With Frequency and Scale Awareness \| IEEE Journals & Magazine \| IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/10638122/authors#authors))/[Code]([chasecjg/FSANet (github.com)](https://github.com/chasecjg/FSANet))                                                                                                                      |

### 2023

| **Year** | **Pub.** | **Title**                                                                                  | **Author**                                                                 | **Links**                                                                                                                                                                                                                                                                                                                                                 |
| -------- | -------- | ------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2023     | NIPS     | SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete Diffusion Process | Mengyu Wang, Henghui Ding, Jun Hao Liew, Jiajun Liu, Yao Zhao, Yunchao Wei | [Paper]([[2312.12425] SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete Diffusion Process (arxiv.org)](https://arxiv.org/abs/2312.12425))/[Code]([MengyuWang826/SegRefiner: SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete Diffusion Process (github.com)](https://github.com/MengyuWang826/SegRefiner)) |

## Promptable
### Preprint

| **Year** | **Pub.** | **Title**                                                                                       | **Author**                                                    | **Links**                                                                                                                                                                                                                                                                                                                                                                       |
| -------- | -------- | ----------------------------------------------------------------------------------------------- | ------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2023     | arXiv    | Promoting Segment Anything Model towards Highly Accurate Dichotomous Image Segmentation         | Xianjie Liu, Keren Fu, Qijun Zhao                             | [Paper]([[2401.00248] Promoting Segment Anything Model towards Highly Accurate Dichotomous Image Segmentation (arxiv.org)](https://arxiv.org/abs/2401.00248))/[Code]([Tennine2077/DIS-SAM: This is the official pytorch implementation of DIS-SAM. (github.com)](https://github.com/Tennine2077/DIS-SAM))                                                                       |
| 2023     | arXiv    | SU-SAM: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes | Yiran Song, Qianyu Zhou, Xuequan Lu, Zhiwen Shao, Lizhuang Ma | [Paper]([[2401.17803] SU-SAM: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes (arxiv.org)](https://arxiv.org/abs/2401.17803))/[Code]([zongzi13545329/SimAda: Official code for SimAda: A Simple Unified Framework for Adapting Segment Anything Model in Underperformed Scenes (github.com)](https://github.com/zongzi13545329/SimAda)) |


### 2024
| **Year** | **Pub.** | **Title**                                                                                   | **Author**                                                                                   | **Links**                                                                                                                                                                                                                                                                                                                                                                                                              |
| -------- | -------- | ------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2024     | ACMMM    | Segment Anything with Precise Interaction                                                   | Mengzhen Liu, Mengyu Wang, Henghui Ding, Yilong Xu, Yao Zhao, Yunchao Wei                    | [Paper]([Segment Anything with Precise Interaction (openreview.net)](https://openreview.net/pdf?id=lD9A7SS4BP))/Code                                                                                                                                                                                                                                                                                                   |
| 2024     | CVPR     | Rethinking Interactive Image Segmentation with Low Latency High Quality and Diverse Prompts | Qin Liu, Jaemin Cho, Mohit Bansal, Marc Niethammer                                           | [Paper]([CVPR 2024 Open Access Repository (thecvf.com)](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Rethinking_Interactive_Image_Segmentation_with_Low_Latency_High_Quality_and_CVPR_2024_paper.html))/[Code]([uncbiag/SegNext: Rethinking Interactive Image Segmentation with Low Latency, High Quality, and Diverse Prompts (CVPR 2024) (github.com)](https://github.com/uncbiag/SegNext))               |
| 2024     | ECCV     | CAT-SAM: Conditional Tuning for Few-Shot Adaptation of Segment Anything Model               | Aoran Xiao, Weihao Xuan, Heli Qi, Yun Xing, Ruijie Ren, Xiaoqin Zhang, Ling Shao, Shijian Lu | [Paper]([[2402.03631] CAT-SAM: Conditional Tuning for Few-Shot Adaptation of Segment Anything Model (arxiv.org)](https://arxiv.org/abs/2402.03631))/[Code]([weihao1115/cat-sam: [ECCV 2024 Oral] The official implementation of "CAT-SAM: Conditional Tuning for Few-Shot Adaptation of Segment Anything Model". (github.com)](https://github.com/weihao1115/cat-sam))                                                 |
| 2024     | ICCV     | BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model                        | Yiran Song, Qianyu Zhou, Xiangtai Li, Deng-Ping Fan, Xuequan Lu, Lizhuang Ma                 | [Paper]([CVPR 2024 Open Access Repository (thecvf.com)](https://openaccess.thecvf.com/content/CVPR2024/html/Song_BA-SAM_Scalable_Bias-Mode_Attention_Mask_for_Segment_Anything_Model_CVPR_2024_paper.html))/[Code]([CVPR 2024 Open Access Repository (thecvf.com)](https://openaccess.thecvf.com/content/CVPR2024/html/Song_BA-SAM_Scalable_Bias-Mode_Attention_Mask_for_Segment_Anything_Model_CVPR_2024_paper.html)) |
| 2024     | ECCV     | Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model            | Haobo Yuan, Xiangtai Li, Lu Qi, Tao Zhang, Ming-Hsuan Yang, Shuicheng Yan, Chen Change Loy   | [Paper]([[2406.19369] Mamba or RWKV: Exploring High-Quality and High-Efficiency Segment Anything Model (arxiv.org)](https://arxiv.org/abs/2406.19369))/[Code]([HarborYuan/ovsam: [ECCV 2024] The official code of paper "Open-Vocabulary SAM". (github.com)](https://github.com/HarborYuan/ovsam))                                                                                                                     |
| 2024     | ICME     | PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation                              | Zhaozhi Xie, Bochen Guan, Weihao Jiang, Muyang Yi, Yue Ding, Hongtao Lu, Lei Zhang           | [Paper]([[2401.13051] PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation (arxiv.org)](https://arxiv.org/abs/2401.13051))/[Code]([xzz2/pa-sam: PA-SAM: Prompt Adapter SAM for High-quality Image Segmentation (github.com)](https://github.com/xzz2/pa-sam))                                                                                                                                                |
| 2024     | PRICAI   | Prior Mask-Guided Highly Accurate<br>Dichotomous Image Segmentation                         | Shanfeng Zhou, Bo Yuan, Keren Fu , Hailun Zhang, and Qijun Zhao                              | Paper/Code                                                                                                                                                                                                                                                                                                                                                                                                             |
### 2023
| **Year** | **Pub.** | **Title**                        | **Author**                                                                               | **Links**                                                                                                                                                                                                                    |
| -------- | -------- | -------------------------------- | ---------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2023     | NIPS     | Segment Anything in High Quality | Lei Ke, Mingqiao Ye, Martin Danelljan, Yifan Liu, Yu-Wing Tai, Chi-Keung Tang, Fisher Yu | [Paper]([[2306.01567] Segment Anything in High Quality (arxiv.org)](https://arxiv.org/abs/2306.01567))/[Code]([SysCV/sam-hq: Segment Anything in High Quality [NeurIPS 2023] (github.com)](https://github.com/SysCV/SAM-HQ)) |